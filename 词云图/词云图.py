import jiebaimport jieba.analysefrom wordcloud import WordCloudimport matplotlib.pyplot as plt# 假设这是您的文本数据，包含汉字text = "绿皮怪兽,lei824,lxyer,fatdragoncat," \       "又是一条不归路,noes,夏雪宜,向东是大海,UGlee," \       "不二青龙,readboy12345,pikachu007,四月风花," \       "ssmxjl,ageg,77657492,coolulf,zhang0519," \       "cortana,felixding,power2010,forwhat"# 使用jieba进行分词words = jieba.lcut(text)# 将分词结果重新组合成一个字符串text_after_jieba = " ".join(words)# 生成词云图，指定字体路径font_path = '/System/Library/Fonts/Supplemental/Songti.ttc'  # 替换为您的字体文件路径wordcloud = WordCloud(width=1000, height=600, font_path=font_path).generate(text)#如果想要把一段话自动拆分，可以用text_after_jieba替换掉text# 显示词云图plt.figure(figsize=(20, 10))plt.imshow(wordcloud, interpolation='bilinear')plt.axis("off")plt.show()